{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:10:57.367705Z","iopub.status.busy":"2024-01-19T15:10:57.367126Z","iopub.status.idle":"2024-01-19T15:11:10.415388Z","shell.execute_reply":"2024-01-19T15:11:10.414388Z","shell.execute_reply.started":"2024-01-19T15:10:57.367656Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np\n","import os\n","import PIL\n","import PIL.Image\n","import tensorflow as tf\n","import tensorflow_datasets as tfds"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:10.419124Z","iopub.status.busy":"2024-01-19T15:11:10.418622Z","iopub.status.idle":"2024-01-19T15:11:10.424209Z","shell.execute_reply":"2024-01-19T15:11:10.423368Z","shell.execute_reply.started":"2024-01-19T15:11:10.419098Z"},"trusted":true},"outputs":[],"source":["DATA_DIR = '../input/ear-dataset/EarVN1.0 dataset/Images'\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:10.425756Z","iopub.status.busy":"2024-01-19T15:11:10.425423Z","iopub.status.idle":"2024-01-19T15:11:14.187810Z","shell.execute_reply":"2024-01-19T15:11:14.186900Z","shell.execute_reply.started":"2024-01-19T15:11:10.425723Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 28412 files belonging to 164 classes.\n","Using 24151 files for training.\n"]}],"source":["train_val_ds = tf.keras.utils.image_dataset_from_directory(\n","  DATA_DIR,\n","  validation_split=0.15,\n","  label_mode='int',\n","  subset=\"training\",\n","  seed=999,\n","  image_size=(IMG_HEIGHT, IMG_WIDTH),\n","  batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:14.191220Z","iopub.status.busy":"2024-01-19T15:11:14.190530Z","iopub.status.idle":"2024-01-19T15:11:19.817257Z","shell.execute_reply":"2024-01-19T15:11:19.816376Z","shell.execute_reply.started":"2024-01-19T15:11:14.191184Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 28412 files belonging to 164 classes.\n","Using 4261 files for validation.\n"]}],"source":["test_ds = tf.keras.utils.image_dataset_from_directory(\n","  DATA_DIR,\n","  validation_split=0.15,\n","  label_mode='int',\n","  subset=\"validation\",\n","  seed=999,\n","  image_size=(IMG_HEIGHT, IMG_WIDTH),\n","  batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:19.818765Z","iopub.status.busy":"2024-01-19T15:11:19.818490Z","iopub.status.idle":"2024-01-19T15:11:19.828742Z","shell.execute_reply":"2024-01-19T15:11:19.827558Z","shell.execute_reply.started":"2024-01-19T15:11:19.818740Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=int64, numpy=755>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_val_batches = tf.data.experimental.cardinality(train_val_ds)\n","train_val_batches"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:19.830372Z","iopub.status.busy":"2024-01-19T15:11:19.830082Z","iopub.status.idle":"2024-01-19T15:11:19.968914Z","shell.execute_reply":"2024-01-19T15:11:19.968016Z","shell.execute_reply.started":"2024-01-19T15:11:19.830328Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["755\n","604\n","151\n"]}],"source":["TOTAL_TRAIN_VAL = len(train_val_ds)\n","print(TOTAL_TRAIN_VAL)\n","train_ds = train_val_ds.take(int(8 * train_val_batches / 10))\n","val_ds = train_val_ds.skip(int(8 * train_val_batches / 10))\n","print(len(train_ds))\n","print(len(val_ds))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:19.970236Z","iopub.status.busy":"2024-01-19T15:11:19.969979Z","iopub.status.idle":"2024-01-19T15:11:19.976330Z","shell.execute_reply":"2024-01-19T15:11:19.975275Z","shell.execute_reply.started":"2024-01-19T15:11:19.970213Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<_TakeDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_ds"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:19.978170Z","iopub.status.busy":"2024-01-19T15:11:19.977606Z","iopub.status.idle":"2024-01-19T15:11:25.159720Z","shell.execute_reply":"2024-01-19T15:11:25.158740Z","shell.execute_reply.started":"2024-01-19T15:11:19.978137Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n","82420632/82420632 [==============================] - 0s 0us/step\n"]}],"source":["base_model_EfficientNetV2S = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(224, 224, 3)\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:25.162326Z","iopub.status.busy":"2024-01-19T15:11:25.162038Z","iopub.status.idle":"2024-01-19T15:11:26.879649Z","shell.execute_reply":"2024-01-19T15:11:26.878874Z","shell.execute_reply.started":"2024-01-19T15:11:25.162301Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import RMSprop\n","from keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D\n","\n","model = tf.keras.Sequential()\n","model.add(base_model_EfficientNetV2S)\n","model.add(GlobalAveragePooling2D())\n","model.add(Dense(4096, activation = 'relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(164, activation = 'softmax'))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:26.880878Z","iopub.status.busy":"2024-01-19T15:11:26.880623Z","iopub.status.idle":"2024-01-19T15:11:26.947396Z","shell.execute_reply":"2024-01-19T15:11:26.946419Z","shell.execute_reply.started":"2024-01-19T15:11:26.880857Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," efficientnetv2-s (Function  (None, 7, 7, 1280)        20331360  \n"," al)                                                             \n","                                                                 \n"," global_average_pooling2d (  (None, 1280)              0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n"," dense (Dense)               (None, 4096)              5246976   \n","                                                                 \n"," dropout (Dropout)           (None, 4096)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 164)               671908    \n","                                                                 \n","=================================================================\n","Total params: 26250244 (100.14 MB)\n","Trainable params: 26096372 (99.55 MB)\n","Non-trainable params: 153872 (601.06 KB)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:26.948807Z","iopub.status.busy":"2024-01-19T15:11:26.948529Z","iopub.status.idle":"2024-01-19T15:11:26.977253Z","shell.execute_reply":"2024-01-19T15:11:26.976583Z","shell.execute_reply.started":"2024-01-19T15:11:26.948784Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras import optimizers, losses\n","\n","model.compile(optimizer=optimizers.Adam(learning_rate=3e-4), loss='sparse_categorical_crossentropy', metrics='accuracy')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:26.978655Z","iopub.status.busy":"2024-01-19T15:11:26.978313Z","iopub.status.idle":"2024-01-19T15:11:26.984375Z","shell.execute_reply":"2024-01-19T15:11:26.983551Z","shell.execute_reply.started":"2024-01-19T15:11:26.978624Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","mc = ModelCheckpoint(\n","    filepath='./best_efficientnetv2s_model_epoch={epoch:02d}_acc={val_accuracy:0.4f}.h5',\n","    monitor=\"val_accuracy\",\n","    verbose=1,\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode='max',\n","    save_freq='epoch'\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T15:11:31.088393Z","iopub.status.busy":"2024-01-19T15:11:31.087902Z","iopub.status.idle":"2024-01-19T15:44:21.697717Z","shell.execute_reply":"2024-01-19T15:44:21.696746Z","shell.execute_reply.started":"2024-01-19T15:11:31.088355Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2024-01-19 15:12:05.355422: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/efficientnetv2-s/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"]},{"name":"stdout","output_type":"stream","text":["604/604 [==============================] - ETA: 0s - loss: 2.8609 - accuracy: 0.3246\n","Epoch 1: val_accuracy improved from -inf to 0.66307, saving model to ./best_efficientnetv2s_model_epoch=01_acc=0.6631.h5\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["604/604 [==============================] - 278s 318ms/step - loss: 2.8609 - accuracy: 0.3246 - val_loss: 1.2328 - val_accuracy: 0.6631\n","Epoch 2/10\n","604/604 [==============================] - ETA: 0s - loss: 0.8581 - accuracy: 0.7610\n","Epoch 2: val_accuracy improved from 0.66307 to 0.81982, saving model to ./best_efficientnetv2s_model_epoch=02_acc=0.8198.h5\n","604/604 [==============================] - 189s 313ms/step - loss: 0.8581 - accuracy: 0.7610 - val_loss: 0.6757 - val_accuracy: 0.8198\n","Epoch 3/10\n","604/604 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8841\n","Epoch 3: val_accuracy improved from 0.81982 to 0.83662, saving model to ./best_efficientnetv2s_model_epoch=03_acc=0.8366.h5\n","604/604 [==============================] - 188s 311ms/step - loss: 0.3906 - accuracy: 0.8841 - val_loss: 0.6377 - val_accuracy: 0.8366\n","Epoch 4/10\n","604/604 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.9237\n","Epoch 4: val_accuracy improved from 0.83662 to 0.83786, saving model to ./best_efficientnetv2s_model_epoch=04_acc=0.8379.h5\n","604/604 [==============================] - 189s 312ms/step - loss: 0.2544 - accuracy: 0.9237 - val_loss: 0.6582 - val_accuracy: 0.8379\n","Epoch 5/10\n","604/604 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9370\n","Epoch 5: val_accuracy improved from 0.83786 to 0.85217, saving model to ./best_efficientnetv2s_model_epoch=05_acc=0.8522.h5\n","604/604 [==============================] - 188s 310ms/step - loss: 0.1999 - accuracy: 0.9370 - val_loss: 0.6261 - val_accuracy: 0.8522\n","Epoch 6/10\n","604/604 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.9447\n","Epoch 6: val_accuracy did not improve from 0.85217\n","604/604 [==============================] - 187s 310ms/step - loss: 0.1751 - accuracy: 0.9447 - val_loss: 0.6997 - val_accuracy: 0.8435\n","Epoch 7/10\n","604/604 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.9487\n","Epoch 7: val_accuracy improved from 0.85217 to 0.85714, saving model to ./best_efficientnetv2s_model_epoch=07_acc=0.8571.h5\n","604/604 [==============================] - 187s 310ms/step - loss: 0.1635 - accuracy: 0.9487 - val_loss: 0.6167 - val_accuracy: 0.8571\n","Epoch 8/10\n","604/604 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9576\n","Epoch 8: val_accuracy improved from 0.85714 to 0.86316, saving model to ./best_efficientnetv2s_model_epoch=08_acc=0.8632.h5\n","604/604 [==============================] - 188s 311ms/step - loss: 0.1316 - accuracy: 0.9576 - val_loss: 0.5970 - val_accuracy: 0.8632\n","Epoch 9/10\n","604/604 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9655\n","Epoch 9: val_accuracy improved from 0.86316 to 0.86710, saving model to ./best_efficientnetv2s_model_epoch=09_acc=0.8671.h5\n","604/604 [==============================] - 189s 313ms/step - loss: 0.1139 - accuracy: 0.9655 - val_loss: 0.6127 - val_accuracy: 0.8671\n","Epoch 10/10\n","604/604 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9610\n","Epoch 10: val_accuracy did not improve from 0.86710\n","604/604 [==============================] - 187s 310ms/step - loss: 0.1269 - accuracy: 0.9610 - val_loss: 0.6231 - val_accuracy: 0.8671\n"]}],"source":["results = model.fit(train_ds, validation_data=val_ds, epochs=10, batch_size=32, callbacks=[mc])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4325952,"sourceId":7433567,"sourceType":"datasetVersion"}],"dockerImageVersionId":30635,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
